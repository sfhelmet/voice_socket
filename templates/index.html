<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Chat</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.0.1/socket.io.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            text-align: center;
        }
        .controls {
            margin: 20px 0;
        }
        button {
            padding: 10px 20px;
            margin: 0 10px;
            font-size: 16px;
            cursor: pointer;
        }
        #status {
            margin: 20px 0;
            font-weight: bold;
        }
        .recording {
            color: red;
        }
        .volume-meter {
            width: 100%;
            height: 20px;
            background-color: #f0f0f0;
            border-radius: 10px;
            margin: 20px 0;
            overflow: hidden;
        }
        .volume-level {
            height: 100%;
            background-color: #4CAF50;
            width: 0%;
            transition: width 0.1s;
        }
        .input-indicator {
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 20px 0;
        }
        .input-dot {
            width: 15px;
            height: 15px;
            border-radius: 50%;
            background-color: #ccc;
            margin-right: 10px;
        }
        .input-dot.active {
            background-color: #4CAF50;
            box-shadow: 0 0 10px #4CAF50;
        }
    </style>
</head>
<body>
    <h1>Voice Chat</h1>
    <div id="status">Ready to chat</div>
    <div class="input-indicator">
        <div class="input-dot" id="inputDot"></div>
        <span>Input Level</span>
    </div>
    <div class="volume-meter">
        <div class="volume-level" id="volumeLevel"></div>
    </div>
    <div class="controls">
        <button id="recordButton">Start Chat</button>
        <button id="stopButton" disabled>Stop Chat</button>
    </div>

    <script>
        const socket = io();
        const recordButton = document.getElementById('recordButton');
        const stopButton = document.getElementById('stopButton');
        const statusElement = document.getElementById('status');
        const volumeLevel = document.getElementById('volumeLevel');
        const inputDot = document.getElementById('inputDot');

        let audioContext;
        let sourceNode;
        let processorNode;
        let analyserNode;
        let isRecording = false;
        let lastProcessTime = 0;

        // Buffer for playback
        let playbackQueue = [];
        let isPlaying = false;
        let latencyHistory = [];
        const MAX_LATENCY_HISTORY = 100;

        async function initAudio() {
            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                sourceNode = audioContext.createMediaStreamSource(stream);
                
                // Create analyser node for volume visualization
                analyserNode = audioContext.createAnalyser();
                analyserNode.fftSize = 128; // Reduced from 256 for faster processing
                analyserNode.smoothingTimeConstant = 0.3; // Reduced smoothing for faster response
                const bufferLength = analyserNode.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);
                
                // Reduced buffer size for lower latency
                processorNode = audioContext.createScriptProcessor(1024, 1, 1);

                processorNode.onaudioprocess = (e) => {
                    if (!isRecording) return;
                    
                    const currentTime = performance.now();
                    const inputData = e.inputBuffer.getChannelData(0);
                    
                    // Calculate RMS value for volume
                    let sum = 0;
                    for (let i = 0; i < inputData.length; i++) {
                        sum += inputData[i] * inputData[i];
                    }
                    const rms = Math.sqrt(sum / inputData.length);
                    const db = 20 * Math.log10(rms);
                    const volume = Math.min(100, Math.max(0, (db + 100) * 1.5));
                    
                    // Update visual indicators
                    volumeLevel.style.width = `${volume}%`;
                    inputDot.classList.toggle('active', volume > 20);
                    
                    // Convert and send audio data
                    const int16Buffer = new Int16Array(inputData.length);
                    for (let i = 0; i < inputData.length; i++) {
                        int16Buffer[i] = inputData[i] * 0x7FFF;
                    }
                    
                    // Add timestamp to track latency
                    const audioData = {
                        timestamp: currentTime,
                        data: int16Buffer.buffer
                    };
                    
                    socket.emit('voice_data', audioData);
                    
                    // Calculate processing time
                    const processTime = performance.now() - currentTime;
                    lastProcessTime = processTime;
                    
                    // Update latency history
                    latencyHistory.push(processTime);
                    if (latencyHistory.length > MAX_LATENCY_HISTORY) {
                        latencyHistory.shift();
                    }
                };

                // Optimized audio node connections
                sourceNode.connect(analyserNode);
                analyserNode.connect(processorNode);
                processorNode.connect(audioContext.destination);

                recordButton.disabled = false;
                statusElement.textContent = "Ready to chat";
            } catch (err) {
                console.error("Error in audio initialization:", err);
                statusElement.textContent = "Error: " + err.message;
            }
        }

        recordButton.onclick = () => {
            if (isRecording) return;
            isRecording = true;
            recordButton.disabled = true;
            stopButton.disabled = false;
            statusElement.textContent = "Chatting...";
            statusElement.classList.add("recording");
            
            // Resume audio context if it was suspended
            if (audioContext.state === 'suspended') {
                audioContext.resume().then(() => {
                    console.log("AudioContext resumed");
                });
            }
        };

        stopButton.onclick = () => {
            if (!isRecording) return;
            isRecording = false;
            recordButton.disabled = false;
            stopButton.disabled = true;
            statusElement.textContent = "Ready to chat";
            statusElement.classList.remove("recording");
            volumeLevel.style.width = "0%";
            inputDot.classList.remove('active');
        };

        // Play received audio with latency compensation
        socket.on('voice_data', (audioData) => {
            const receiveTime = performance.now();
            const latency = receiveTime - audioData.timestamp;
            
            // Add to playback queue with timestamp
            playbackQueue.push({
                data: audioData.data,
                timestamp: audioData.timestamp
            });
            
            if (!isPlaying) playFromQueue();
        });

        function playFromQueue() {
            if (playbackQueue.length === 0) {
                isPlaying = false;
                return;
            }
            
            isPlaying = true;
            const audioItem = playbackQueue.shift();
            const currentTime = performance.now();
            const latency = currentTime - audioItem.timestamp;
            
            // Skip if too much latency
            if (latency > 500) { // Skip if more than 500ms late
                playFromQueue();
                return;
            }
            
            const arrayBuffer = audioItem.data;
            const int16Array = new Int16Array(arrayBuffer);
            const float32Array = new Float32Array(int16Array.length);
            
            for (let i = 0; i < int16Array.length; i++) {
                float32Array[i] = int16Array[i] / 0x7FFF;
            }
            
            const audioBuffer = audioContext.createBuffer(1, float32Array.length, audioContext.sampleRate);
            audioBuffer.copyToChannel(float32Array, 0);
            
            const source = audioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(audioContext.destination);
            source.onended = playFromQueue;
            source.start();
        }

        window.onload = initAudio;
    </script>
</body>
</html>